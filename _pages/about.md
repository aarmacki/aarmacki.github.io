---
permalink: /
title: "About"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a fifth year PhD student at Carnegie Mellon University, advised by prof. [Soummya Kar](https://users.ece.cmu.edu/~soummyak/index.html). Broadly, my interest lie in signal processing and machine learning. More specifically, I am interested in theoretical guarantees of both centralized and large-scale distributed learning systems. Recent projects included establishing learning guarantees in the presence of various notions of heterogeneity, e.g., statistical (non-IID distributions) [(paper)](https://arxiv.org/abs/2209.10866), or system heterogeneity (varying communication or computation capabilities) [(paper)](https://eurasip.org/Proceedings/Eusipco/Eusipco2023/pdfs/0000875.pdf), as well as learning guarantees under heavy-tailed noise [(paper)](https://arxiv.org/abs/2310.18784).
 
If you have any questions about my research, or believe our interests are synergic, feel free to [reach out](mailto:aarmacki@andrew.cmu.edu).

News
====
* October 2024 - A new preprint is out. Title: ["Large Deviations and Improved Mean-squared Error Rates of Nonlinear SGD: Heavy-tailed Noise and Power of Symmetry''](https://arxiv.org/abs/2410.15637).
* October 2024 - A new preprint is out. Title: ["Nonlinear Stochastic Gradient Descent and Heavy-tailed Noise: A Unified Framework and High-probability Guarantees''](https://arxiv.org/abs/2410.13954).
* February 2024 - A new preprint is out. Title: ["A Unified Framework for Gradient-based Clustering of Distributed Data''](https://arxiv.org/abs/2402.01302).
* December 2023 - Our paper ["A One-shot Framework for Distributed Clustered Learning in Heterogeneous Environments''](https://arxiv.org/abs/2209.10866) got accepted at IEEE Transactions on Signal Processing.
* October 2023 - A new preprint is out. Title: ["High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise''](https://arxiv.org/abs/2310.18784).